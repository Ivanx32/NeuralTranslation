{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import os;\n",
    "import pickle;\n",
    "import numpy as np;\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence;\n",
    "from keras.models import Sequential,load_model;\n",
    "from keras.utils.vis_utils import plot_model;\n",
    "\n",
    "\n",
    "from keras.models import Model;\n",
    "from keras.layers.embeddings import Embedding;\n",
    "from keras.models import Sequential,load_model;\n",
    "from keras.optimizers import rmsprop,adam,adagrad,SGD;\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau, CSVLogger;\n",
    "from keras.preprocessing.text import text_to_word_sequence,one_hot,Tokenizer;\n",
    "from keras.layers import Input,Dense,merge,Dropout,BatchNormalization,Activation,Conv1D;\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# setting current working directory\n",
    "\n",
    "DIR='/home/ivan/Dropbox/Projects/OldLang/code/ByteNet-Keras-master'\n",
    "WKDIR = DIR\n",
    "data_path = '/home/ivan/Dropbox/Projects/OldLang/data/ancient/' + 'processed_v6_maxlen205.txt' #!!!\n",
    "\n",
    "batch_size=64\n",
    "#N=15040\n",
    "maxlen=205;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/ivan/Dropbox/Projects/OldLang/code/ByteNet-Keras-master/models/' +'conv1d_54'#'conv1d_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size, data_path, N=None):\n",
    "    \n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    \n",
    "    if N is not None:\n",
    "        lines = lines[:N]\n",
    "\n",
    "    anc_list = []\n",
    "    rus_list = []\n",
    "    for line in lines[: len(lines) - 1]:\n",
    "        anc, rus = line.split('\\t')\n",
    "        anc_list += [anc]\n",
    "        rus_list += [rus]\n",
    "    \n",
    "    French = rus_list\n",
    "    English = anc_list\n",
    "    English = [i + \"\\n\" for i in English];# add ending signal at the sequence end\n",
    "    \n",
    "    if batch_size is not None:\n",
    "        while 1:\n",
    "            if len(English) % batch_size != 0:\n",
    "                del English[-1];\n",
    "                del French[-1];\n",
    "            else:\n",
    "                break;\n",
    "    return French,English;\n",
    "\n",
    "\n",
    "#lan1, lan2 = load_dataset(batch_size=64, data_path=data_path, N=None) #!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_vacabulary(French,English):\n",
    "    all_eng_words = [];\n",
    "    all_french_words = [];\n",
    "    for i in np.arange(0, len(French)):\n",
    "        all_eng_words.append(English[i]);\n",
    "        all_french_words.append(French[i]);\n",
    "    tokeng = Tokenizer(char_level=True);\n",
    "    tokeng.fit_on_texts(all_eng_words);\n",
    "    eng_index = tokeng.word_index;  # build character to index dictionary\n",
    "    index_eng = dict((eng_index[i], i) for i in eng_index);\n",
    "    tokita = Tokenizer(char_level=True);\n",
    "    tokita.fit_on_texts(all_french_words);\n",
    "    french_index = tokita.word_index;  # build character to index dictionary\n",
    "    index_french = dict((french_index[i], i) for i in french_index);\n",
    "    return (eng_index,french_index,index_eng,index_french);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "French,English=load_dataset(batch_size=batch_size, data_path=data_path, N=None);\n",
    "eng_index, french_index, index_eng, index_french=build_vacabulary(French,English);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({' ': 1,\n",
       "  'о': 2,\n",
       "  'и': 3,\n",
       "  'е': 4,\n",
       "  'а': 5,\n",
       "  'с': 6,\n",
       "  'т': 7,\n",
       "  'н': 8,\n",
       "  'в': 9,\n",
       "  'р': 10,\n",
       "  'м': 11,\n",
       "  'л': 12,\n",
       "  'д': 13,\n",
       "  'у': 14,\n",
       "  'п': 15,\n",
       "  'к': 16,\n",
       "  'я': 17,\n",
       "  'ъ': 18,\n",
       "  'г': 19,\n",
       "  'ѣ': 20,\n",
       "  'б': 21,\n",
       "  'ь': 22,\n",
       "  'ж': 23,\n",
       "  'ы': 24,\n",
       "  'з': 25,\n",
       "  '\\n': 26,\n",
       "  'ш': 27,\n",
       "  'х': 28,\n",
       "  'ч': 29,\n",
       "  'ю': 30,\n",
       "  'й': 31,\n",
       "  'ц': 32,\n",
       "  'щ': 33,\n",
       "  'ф': 34,\n",
       "  '0': 35,\n",
       "  '6': 36,\n",
       "  '1': 37,\n",
       "  '4': 38,\n",
       "  '5': 39,\n",
       "  '3': 40,\n",
       "  '7': 41,\n",
       "  '2': 42,\n",
       "  '8': 43,\n",
       "  '9': 44,\n",
       "  'ѝ': 45,\n",
       "  'э': 46,\n",
       "  'і': 47,\n",
       "  'ё': 48,\n",
       "  'à': 49,\n",
       "  'c': 50,\n",
       "  'i': 51},\n",
       " {' ': 1,\n",
       "  'о': 2,\n",
       "  'и': 3,\n",
       "  'е': 4,\n",
       "  'а': 5,\n",
       "  'с': 6,\n",
       "  'т': 7,\n",
       "  'н': 8,\n",
       "  'в': 9,\n",
       "  'л': 10,\n",
       "  'р': 11,\n",
       "  'м': 12,\n",
       "  'д': 13,\n",
       "  'к': 14,\n",
       "  'п': 15,\n",
       "  'у': 16,\n",
       "  'г': 17,\n",
       "  'я': 18,\n",
       "  'б': 19,\n",
       "  'ы': 20,\n",
       "  'ь': 21,\n",
       "  'з': 22,\n",
       "  'ч': 23,\n",
       "  'й': 24,\n",
       "  'ж': 25,\n",
       "  'х': 26,\n",
       "  'ш': 27,\n",
       "  'ю': 28,\n",
       "  'ц': 29,\n",
       "  'щ': 30,\n",
       "  'э': 31,\n",
       "  'ф': 32,\n",
       "  '6': 33,\n",
       "  '4': 34,\n",
       "  '7': 35,\n",
       "  '5': 36,\n",
       "  'ъ': 37,\n",
       "  '1': 38,\n",
       "  '0': 39,\n",
       "  '3': 40,\n",
       "  '2': 41,\n",
       "  '9': 42,\n",
       "  '8': 43,\n",
       "  'ο': 44,\n",
       "  'a': 45,\n",
       "  'κ': 46,\n",
       "  'h': 47,\n",
       "  'e': 48,\n",
       "  'y': 49,\n",
       "  'ё': 50,\n",
       "  'c': 51,\n",
       "  'é': 52,\n",
       "  't': 53,\n",
       "  'o': 54},\n",
       " {1: ' ',\n",
       "  2: 'о',\n",
       "  3: 'и',\n",
       "  4: 'е',\n",
       "  5: 'а',\n",
       "  6: 'с',\n",
       "  7: 'т',\n",
       "  8: 'н',\n",
       "  9: 'в',\n",
       "  10: 'р',\n",
       "  11: 'м',\n",
       "  12: 'л',\n",
       "  13: 'д',\n",
       "  14: 'у',\n",
       "  15: 'п',\n",
       "  16: 'к',\n",
       "  17: 'я',\n",
       "  18: 'ъ',\n",
       "  19: 'г',\n",
       "  20: 'ѣ',\n",
       "  21: 'б',\n",
       "  22: 'ь',\n",
       "  23: 'ж',\n",
       "  24: 'ы',\n",
       "  25: 'з',\n",
       "  26: '\\n',\n",
       "  27: 'ш',\n",
       "  28: 'х',\n",
       "  29: 'ч',\n",
       "  30: 'ю',\n",
       "  31: 'й',\n",
       "  32: 'ц',\n",
       "  33: 'щ',\n",
       "  34: 'ф',\n",
       "  35: '0',\n",
       "  36: '6',\n",
       "  37: '1',\n",
       "  38: '4',\n",
       "  39: '5',\n",
       "  40: '3',\n",
       "  41: '7',\n",
       "  42: '2',\n",
       "  43: '8',\n",
       "  44: '9',\n",
       "  45: 'ѝ',\n",
       "  46: 'э',\n",
       "  47: 'і',\n",
       "  48: 'ё',\n",
       "  49: 'à',\n",
       "  50: 'c',\n",
       "  51: 'i'},\n",
       " {1: ' ',\n",
       "  2: 'о',\n",
       "  3: 'и',\n",
       "  4: 'е',\n",
       "  5: 'а',\n",
       "  6: 'с',\n",
       "  7: 'т',\n",
       "  8: 'н',\n",
       "  9: 'в',\n",
       "  10: 'л',\n",
       "  11: 'р',\n",
       "  12: 'м',\n",
       "  13: 'д',\n",
       "  14: 'к',\n",
       "  15: 'п',\n",
       "  16: 'у',\n",
       "  17: 'г',\n",
       "  18: 'я',\n",
       "  19: 'б',\n",
       "  20: 'ы',\n",
       "  21: 'ь',\n",
       "  22: 'з',\n",
       "  23: 'ч',\n",
       "  24: 'й',\n",
       "  25: 'ж',\n",
       "  26: 'х',\n",
       "  27: 'ш',\n",
       "  28: 'ю',\n",
       "  29: 'ц',\n",
       "  30: 'щ',\n",
       "  31: 'э',\n",
       "  32: 'ф',\n",
       "  33: '6',\n",
       "  34: '4',\n",
       "  35: '7',\n",
       "  36: '5',\n",
       "  37: 'ъ',\n",
       "  38: '1',\n",
       "  39: '0',\n",
       "  40: '3',\n",
       "  41: '2',\n",
       "  42: '9',\n",
       "  43: '8',\n",
       "  44: 'ο',\n",
       "  45: 'a',\n",
       "  46: 'κ',\n",
       "  47: 'h',\n",
       "  48: 'e',\n",
       "  49: 'y',\n",
       "  50: 'ё',\n",
       "  51: 'c',\n",
       "  52: 'é',\n",
       "  53: 't',\n",
       "  54: 'o'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_index, french_index, index_eng, index_french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1271: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "model=load_model(model_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_2_vec(input):\n",
    "    source=input[0];target=input[1];\n",
    "    source_vec=np.zeros((1,maxlen+1),dtype=np.uint16);\n",
    "    target_vec=np.zeros((1,maxlen),dtype=np.uint16);\n",
    "    for i,ele1 in enumerate(source):\n",
    "        source_vec[0,i]=french_index[ele1];\n",
    "    for j,ele2 in enumerate(target):\n",
    "        target_vec[0,j]=eng_index[ele2];\n",
    "    return (source_vec,target_vec);\n",
    "\n",
    "def T(sentence):\n",
    "    vec=input_2_vec(sentence);\n",
    "    source_vec=vec[0];target_vec=vec[1];\n",
    "    t0=np.zeros((1,1,500),dtype=np.uint8);\n",
    "    predict=model.predict([source_vec,target_vec,t0])[0];\n",
    "    predict_max=np.argmax(predict,axis=-1);\n",
    "    answers=[index_eng[j+1] for j in predict_max];\n",
    "    a=\"\".join(answers);\n",
    "    return a;\n",
    "\n",
    "#plot_model(model, to_file=\"model.png\", show_shapes=True)\n",
    "def translate(french_sentence):\n",
    "    french_sentence = preproc_test(french_sentence)\n",
    "    process_english_sentence=\"\";\n",
    "    length=0;\n",
    "    while 1:\n",
    "        predicted_english_sentence=T([french_sentence,process_english_sentence]);\n",
    "        process_english_sentence=predicted_english_sentence[:length+1];length+=1;\n",
    "        if process_english_sentence[-1]==\"\\n\":break;\n",
    "        if length>=maxlen+1:break;\n",
    "        #if length%10==0:print(\"{} completed\".format(str(length*maxlen**-1)));\n",
    "    return process_english_sentence.strip();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_test(line):\n",
    "    \n",
    "    replace_dict = OrderedDict({\n",
    "                                    '<...>': '',\n",
    "                                    '«': '', '»': '',\n",
    "                                    '...': '',\n",
    "                                    '!.': '.',\n",
    "                                    '!': '.',\n",
    "                                    '?.': '.',\n",
    "                                    '?': '.',     \n",
    "                                    ';': ',', #!!!\n",
    "    })\n",
    "    \n",
    "    for k in replace_dict.keys():\n",
    "        line = line.replace(k, replace_dict[k])\n",
    "        \n",
    "    \n",
    "    line = re.sub(r\"\\[\\d+\\]\", \"\", line)\n",
    "    line = re.sub(r\"\\(\\d+\\)\", \"\", line)\n",
    "    line = re.sub(r\" \\.\", \".\", line)\n",
    "\n",
    "    replace_dict_2 = OrderedDict({\n",
    "        '.,': '.',\n",
    "        '—': '',\n",
    "        '“': '',\n",
    "        '”': '',\n",
    "        '’': '',\n",
    "        '˝': '',\n",
    "        '\"': '',\n",
    "        '´': '',\n",
    "        '(': '', ')': '',\n",
    "        '<': '', '>': '',\n",
    "        '-': '', \n",
    "        '„': '',\n",
    "        '̀': '',\n",
    "        '́': '',\n",
    "        '*': '',\n",
    "        '…': '',  \n",
    "        \"'\": '',\n",
    "        '{': '',\n",
    "        '}': '',\n",
    "                                \n",
    "    })\n",
    "    \n",
    "    for k in replace_dict_2.keys():\n",
    "        line = line.replace(k, replace_dict_2[k])\n",
    "                \n",
    "\n",
    "    line = line.replace('\\t', ' ')\n",
    "    line = line.replace(',', '') #!!\n",
    "    #line = line.replace('.', '') #!!!\n",
    "    line = line.replace(':', '')\n",
    "    \n",
    "    line = line.replace('.', '')\n",
    "    \n",
    "    line = line.lower() #!!!\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"И сказал, смеясь, Иван Васильевич\n",
    "Твоему горю пособить постараюся\n",
    "И пошли дары драгоценные\n",
    "И сказал мне так тихим шепотом\n",
    "Ох ты гой еси, царь Иван Васильевич!\n",
    "Обманул тебя твой лукавый раб\n",
    "И такое слово ему молвили\n",
    "Когда сизый орел зовет голосом\n",
    "А такой обиды не стерпеть душе\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Оригинал</th>\n",
       "      <th>Сгенерировано</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>И сказал, смеясь, Иван Васильевич</td>\n",
       "      <td>и рече князи сынъ иван василковъ великий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Твоему горю пособить постараюся</td>\n",
       "      <td>твоему господи поспѣшити да сподобиться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>И пошли дары драгоценные</td>\n",
       "      <td>и поидоша дарования дождеся</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>И сказал мне так тихим шепотом</td>\n",
       "      <td>и глагола ми тако те позаемь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ох ты гой еси, царь Иван Васильевич!</td>\n",
       "      <td>охъ же сей царь и васильевича видѣх</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Обманул тебя твой лукавый раб</td>\n",
       "      <td>помышляше братие твоя рабъ врус</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>И такое слово ему молвили</td>\n",
       "      <td>и тако словесе моляшеся</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Когда сизый орел зовет голосом</td>\n",
       "      <td>и сиа судом отроча велми глаголаше</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>А такой обиды не стерпеть душе</td>\n",
       "      <td>такоже и обрѣте не достоит душю</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Оригинал  \\\n",
       "0     И сказал, смеясь, Иван Васильевич   \n",
       "1       Твоему горю пособить постараюся   \n",
       "2              И пошли дары драгоценные   \n",
       "3        И сказал мне так тихим шепотом   \n",
       "4  Ох ты гой еси, царь Иван Васильевич!   \n",
       "5         Обманул тебя твой лукавый раб   \n",
       "6             И такое слово ему молвили   \n",
       "7        Когда сизый орел зовет голосом   \n",
       "8        А такой обиды не стерпеть душе   \n",
       "\n",
       "                              Сгенерировано  \n",
       "0  и рече князи сынъ иван василковъ великий  \n",
       "1   твоему господи поспѣшити да сподобиться  \n",
       "2               и поидоша дарования дождеся  \n",
       "3              и глагола ми тако те позаемь  \n",
       "4       охъ же сей царь и васильевича видѣх  \n",
       "5           помышляше братие твоя рабъ врус  \n",
       "6                   и тако словесе моляшеся  \n",
       "7        и сиа судом отроча велми глаголаше  \n",
       "8           такоже и обрѣте не достоит душю  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "for x in s.split('\\n'):\n",
    "    y = translate(x)\n",
    "    df += [[x, y]]\n",
    "    \n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['Оригинал', \"Сгенерировано\"]   \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
